{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac90c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    "URLS = {\n",
    "    \"indeed\": \"https://ie.indeed.com\"\n",
    "}\n",
    "\n",
    "def extract_site(site: str, skill_name: str, location=\"Ireland\", num_page=0) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Extracts the HTML from the requested site.\n",
    "\n",
    "    Parameters:\n",
    "    - site (str): The website to extract data from.\n",
    "    - skill_name (str): The skill or job title to search for.\n",
    "    - location (str): The location where the job search should be conducted. Defaults to \"Ireland\".\n",
    "    - num_page (int): The number of pages to scrape. If set to 0, scrapes only first page. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "    - soup (BeautifulSoup): The BeautifulSoup object containing the parsed HTML.\n",
    "    \"\"\"\n",
    "    options = Options()\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    url = \"\"\n",
    "    if site == \"indeed\":\n",
    "        url = (\n",
    "            URLS[site]\n",
    "            + f\"/jobs?q={skill_name.replace(' ', '+')}&l={location}&start={num_page * 10}\"\n",
    "        )\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Let the page load (adjust this time according to your needs)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()  # Close the WebDriver after extracting the HTML\n",
    "    return soup\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the skill name, location, and number of pages\n",
    "    job_data = []\n",
    "    skill_name = \"sustainability\"\n",
    "    location = \"Ireland\"\n",
    "    num_pages = 7 \n",
    "    \n",
    "    # Iterate over each page and extract job information\n",
    "    for page in range(num_pages):\n",
    "        soup = extract_site(site=\"indeed\", skill_name=skill_name, location=location, num_page=page)\n",
    "        job_cards_div = soup.find(\"div\", attrs={\"id\": \"mosaic-provider-jobcards\"})\n",
    "        if job_cards_div:\n",
    "            jobs = job_cards_div.find_all(\"li\", class_=\"css-5lfssm eu4oa1w0\")\n",
    "            for job in jobs:\n",
    "                job_link_elem = job.find('a')\n",
    "                if job_link_elem:\n",
    "                    job_id = job_link_elem.get('data-jk')\n",
    "                    job_title_elem = job.find(\"div\", class_=\"css-dekpa e37uo190\")\n",
    "                    if job_title_elem:\n",
    "                        job_title = job_title_elem.text.strip()\n",
    "                    else:\n",
    "                        job_title = \"N/A\"\n",
    "                    company_name_elem = job.find(\"span\", class_=\"css-92r8pb eu4oa1w0\")\n",
    "                    if company_name_elem:\n",
    "                        company_name = company_name_elem.text.strip()\n",
    "                    else:\n",
    "                        company_name = \"N/A\"\n",
    "                    job_location_elem = job.find(\"div\", class_=\"css-1p0sjhy eu4oa1w0\")\n",
    "                    if job_location_elem:\n",
    "                        job_location = job_location_elem.text.strip()\n",
    "                    else:\n",
    "                        job_location = \"N/A\"\n",
    "                    job_link = f\"https://ie.indeed.com/viewjob?jk={job_id}\"\n",
    "                    job_data.append({\n",
    "                        'Job Title': job_title,\n",
    "                        'Company': company_name,\n",
    "                        'Location': job_location,\n",
    "                        'Link': job_link\n",
    "                    })\n",
    "        else:\n",
    "            print(\"No job cards found on this page.\")\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f042f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(job_data)\n",
    "\n",
    "csv_filename = \"sustainability1.csv\"\n",
    "\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93759c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02842173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
